{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McSAS3, a reimplemented Monte-Carlo analyser for Scattering patterns.\n",
    "==\n",
    "\n",
    "Introduction\n",
    "--\n",
    "The original McSAS (1,2) has been used by many researchers to analyse scattering patterns. This approach can determine form-free parameter distributions from scattering patterns (e.g. size distributions) assuming only a scatterer shape. \n",
    "\n",
    "However, that implementation had fundamental limitations. To resolve these limitations, McSAS3 was developed, a refactoring of the entire codebase to more modern standards. This refactoring has several advantages, chief among them:\n",
    "  - Using the SasModels library from the SasView package, with many tried and tested GPU-accelerated models and model extensions in it. Combined models should also be possible (untested).\n",
    "  - Alternatively, models can be simulated from free-form objects described in STL form via the SPONGE scattering pattern simulator (limited information on the SPONGE in (3)). These can then be used as base objects in McSAS3.\n",
    "  - Multi-core optimization is enabled, each repetition can occupy its own thread\n",
    "  - re-instantiating and rehistogramming an existing optimization is now possible\n",
    "  - All steps in the fitting and histogramming process are extensively documented in a clear, hierarchical NeXus-like structure (HDF5-compatible)\n",
    "  - Completely separated from UI enables scripted analyses of large datasets on servers or clusters\n",
    "  - Modifiable random number pickers for speed improvements, usually linear or inverse logarithmic probability\n",
    "  \n",
    "Usage:\n",
    "--\n",
    "This notebook shows an example usage of McSAS3, leveraging some of the possibilities of the code. However, it does not work automatically, there are bits that need to be adapted. \n",
    "\n",
    "Firstly, in the import section, change the two paths to wherever you have the SasView and McSAS3 codebase installed, respectively. # NOTE: this could be solved with git imports maybe?\n",
    "\n",
    "Secondly, there is the file loading section. Here, you must make sure that your 1D data is loaded correctly, complete with uncertainty estimates. A plot is provided to help you. \n",
    "The McData class supports the following formats:\n",
    "  - 3-column ascii files, which require you to set the csv loader arguments correctly. This data must be in units of Q: 1/nm, I: 1/(m sr), ISigma: 1/(m sr). \n",
    "  - NXcanSAS files are supported # NOTE: double-check. \n",
    "  - pdh files are supported (Anton Paar's 1D format)\n",
    "  - data stored in previous McSAS3 runs are supported\n",
    "  - 2D data must be provided in NXcanSAS format, a compatible HDF5 file (e.g. from DAWN) or from a previous McSAS3 run. \n",
    "\n",
    "Thirdly, both the scattering model, and the optimizer are configured and the optimization is run\n",
    "\n",
    "Fourthly, the histogrammer is set up and provided with a few ranges for a few parameters. Feel free to modify as needed. \n",
    "\n",
    "Fifthly, the reporting functions are demonstrated that create a report very similar to what was produced by the original McSAS code. \n",
    "\n",
    "Lastly, it is shown how the histogrammer can be adjusted and re-run without rerunning the optimizer. \n",
    "\n",
    "Not implemented:\n",
    "--\n",
    "McSAS3 is missing some features that were in the original McSAS. These were left out for one of two reasons, either 1) the authors feel their utility is limited, or 2) we have not yet discovered the best way to implement these. These include:\n",
    "  - Slit- and point smearing. These will be implemented in the future once we figure out how to leverage the implementations in SasModels\n",
    "  - Weighting compensation: this is left out on purpose, as we found in practice most if not all patterns can be fit using inverse volume-weighting on the intensity. Omission simplifies the code, making it easier to maintain\n",
    "  - weighting of resulting histograms other than volume-weighting. As the data in scattering most closely represents volume-weighted size information, this representation is the most accurate. Other weightings are sometimes possible (on a case-by-case basis, depending on the width and shape of the distribution) but this transformation must be done by the user. \n",
    "  - Observability limits. This was found to be the most confusing indicator in the original McSAS, and is represented with similar approximate accuracy by the error bar uncertainty. This may be reimplemented at a later stage an an optional plottable.\n",
    "  \n",
    "  1. https://doi.org/10.1107/S0021889813001295\n",
    "  2. https://doi.org/10.1107/S1600576715007347\n",
    "  3. https://doi.org/10.1038/s41467-020-15422-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "--\n",
    "\n",
    "This section imports the necessary packages (and maybe a few extra for good measure), and shows what models are available in the SasModels library. One way to make sure all required Python modules are installed, is by running:\n",
    "\n",
    "    pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary bits and bobs\n",
    "\n",
    "import h5py, sys, os\n",
    "import numpy as np\n",
    "import pandas\n",
    "# import scipy\n",
    "# import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "# load required modules\n",
    "homedir = os.path.expanduser(\"~\")\n",
    "# disable OpenCL for multiprocessing on CPU\n",
    "os.environ[\"SAS_OPENCL\"] = \"none\"\n",
    "\n",
    "# CHANGE to location where the SasView/sasmodels are installed\n",
    "#sasviewPath = os.path.join(homedir, \"Code\", \"sasmodels\")  # <-- change! \n",
    "#if sasviewPath not in sys.path:\n",
    "#    sys.path.append(sasviewPath)\n",
    "# import from this path\n",
    "import sasmodels\n",
    "import sasmodels.core\n",
    "import sasmodels.direct_model\n",
    "\n",
    "# CHANGE this one to whereever you have mcsas3 installed:\n",
    "# (if its not in the parent directory)\n",
    "mcsasPath = os.path.join(\"..\")\n",
    "if mcsasPath not in sys.path:\n",
    "    sys.path.append(mcsasPath)\n",
    "\n",
    "# import from this path:\n",
    "from mcsas3 import McHat\n",
    "from mcsas3 import McData1D, McData2D\n",
    "from mcsas3.mcmodelhistogrammer import McModelHistogrammer\n",
    "from mcsas3.mcanalysis import McAnalysis\n",
    "# optimizeScalingAndBackground: takes care of the calculation of the reduced chi-squared value, after a least-squares optimization for the scaling and background factors.\n",
    "# McModel: extends the SasModel with information on the parameter set and methods for calculating a total scattering intensity from multiple contributions. It also tracks parameter bounds, random generators and picks.\n",
    "# McOpt: contains mostly settings related to the optimization process. Also keeps track of the contribution to optimize.\n",
    "# McCore: Contains the methods required to do the optimization. \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Data fit using McSAS3\n",
    "== \n",
    "\n",
    "The 1D tests loads the standard McSAS Quickstartdemo dataset, which is a simulated dataset of a trimodal distribution of spheres. These modes are centered around 10, 50 and 100 nm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a filename for documenting the fit:\n",
    "resPath = Path(\"..\", \"testdata\", \"quickstartdemo1_fitResult.h5\")\n",
    "# delete if it exists:\n",
    "if resPath.is_file(): resPath.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading:\n",
    "--\n",
    "We have a class for this, which loads the data, clips and rebins the data as requested. We always recommend rebinning the data to about 100 datapoints per decade in Q as a rule of thumb, to speed up the fitting itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement data:\n",
    "mds = McData1D.McData1D(\n",
    "    filename=Path(\"..\", \"testdata\", \"quickstartdemo1.csv\"),\n",
    "    nbins=0, # no rebinning in this example\n",
    "    dataRange = [0.01, 1], # this clips the data to the specified range\n",
    "\n",
    "    # arguments for pandas.read_csv:\n",
    "    csvargs = {\"sep\" : ';', # field delimiter, for flexible whitespace, use: \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\" (https://stackoverflow.com/questions/15026698/how-to-make-separator-in-pandas-read-csv-more-flexible-wrt-whitespace-for-irreg#15026839)\n",
    "               \"skipinitialspace\" : True, # ignore initial blank spaces\n",
    "               \"skip_blank_lines\" : True, # ignore lines with nothing in them\n",
    "               \"skiprows\" : 0, # skip this many rows before reading data (useful for PDH, which I think has five (?) header rows?)\n",
    "               \"engine\": \"python\", # most flexible\n",
    "               \"header\" : None, # let's not read any column names since they're unlikely to match with our expected column names:\n",
    "               \"names\": [\"Q\", \"I\", \"ISigma\"], # our expected column names\n",
    "               \"index_col\" : False}, # no index column before every row (who does this anyway?)\n",
    ")\n",
    "\n",
    "# store the data and all derivatives in the output file:\n",
    "mds.store(resPath)\n",
    "\n",
    "# plot the loaded data\n",
    "fhs, ahs = plt.subplots(nrows = 1, ncols = 1, figsize = [6, 4])\n",
    "mds.rawData.plot('Q', 'I', yerr= 'ISigma', ax = ahs, label = 'As provided data')\n",
    "mds.clippedData.plot('Q', 'I', yerr= 'ISigma', ax = ahs, label = 'clipped data')\n",
    "mds.binnedData.plot('Q', 'I', yerr= 'ISigma', ax = ahs, label = 'binned data')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Q (1/nm)')\n",
    "plt.ylabel('I (1/(m sr))')\n",
    "# plt.xlim([0.1, 3])\n",
    "print(f'data fed to McSAS3 is {mds.measDataLink}')\n",
    "md = mds.measData.copy() # here we copy the data we want for fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models\n",
    "--\n",
    "Once we are happy with our data, we can choose a fitting model. We have the following models available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me all the available models, 1D and 1D+2D\n",
    "\n",
    "print(\"\\n \\n 1D-only SasModel Models:\\n\")\n",
    "print(\" -- \\n\")\n",
    "\n",
    "for model in sasmodels.core.list_models():\n",
    "    modelInfo = sasmodels.core.load_model_info(model)\n",
    "    if not modelInfo.parameters.has_2d:\n",
    "        print(f\" \\t * {modelInfo.id}\")\n",
    "\n",
    "print(\"\\n \\n 2D- and 1D- SasModel Models:\\n\")\n",
    "print(\" -- \\n\")\n",
    "for model in sasmodels.core.list_models():\n",
    "    modelInfo = sasmodels.core.load_model_info(model)\n",
    "    if modelInfo.parameters.has_2d:\n",
    "        print(f\" \\t * {modelInfo.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, we choose the sphere model, but other models work in a similar manner. These models often contain many parameters special for magnetic (neutron) scattering, which can be safely ignored for X-ray scattering purposes. \n",
    "\n",
    "We can get some information on the default parameters and model information using the following segment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sasmodels.core.load_model_info('sphere')\n",
    "print(\"\\n Current model parameters, their defaults and their units: \\n\") # not sure how to get parameter units yet\n",
    "_=[print(f\"{param.name :>20}: {model.parameters.defaults[param.name]:>8}, {param.units :>12}\") for param in model.parameters.call_parameters]\n",
    "# get some more information:\n",
    "print('\\n == \\n Current model offline documentation:')\n",
    "print(model.docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the optimizer with the model name and its parameters.\n",
    "--\n",
    "Here we use a convenience function McHat (sits on top of everything), that instantiates the optimizer and the model, and stores the configuration in the results structure. In principle, you can then take this preconfigured file with the data and settings, and submit it to some server for running, as it has all the necessary information for the optimization (not for the histogramming yet). Useful for users with limited computing resources. # NOTE: An idea for exploiting free cloud computing resources? :). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configures the model the Monte Carlo optimizer:\n",
    "\n",
    "mh = McHat.McHat(\n",
    "            modelName=\"sphere\", # the model name chosen from the list above\n",
    "            nContrib=300, # number of contributions, 300 normally suffice\n",
    "            modelDType=\"default\", # choose \"fast\" for single-precision calculations at your own risk\n",
    "            fitParameterLimits={\"radius\": (3.14, 314)}, # this is the parameter we want to MC optimize within these bounds\n",
    "            staticParameters={ # these are the parameters we don't want to change:\n",
    "                \"background\": 0, # is optimized separately, always set to zero\n",
    "                \"scaling\": 1, # ibid.\n",
    "                \"sld\": 77.93, # SLD of silver \n",
    "                \"sld_solvent\": 9.45,# SLD of water\n",
    "                },\n",
    "            maxIter=100000, # don't try more than this many iterations\n",
    "            convCrit=1, # convergence criterion, should be 1 if reasonable uncertainty estimates are provided, to prevent over- or under-fitting\n",
    "            nRep=10, # number of independent repetitions of the optimization procedure. 10 for fast, 50-100 for publications\n",
    "            nCores=0, # number of threads to spread this over. Set to 0 for automatic detection of maximum number of threads\n",
    "            seed=None, # random number generator seed. Set to a specific value for reproducible random numbers\n",
    "        )\n",
    "mh.store(resPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = input(\"This will run the optimization whic can take a few minutes. Are you sure? Y/N\")\n",
    "if ans=='Y': mh.run(md, resPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogramming the result\n",
    "--\n",
    "Now that the optimization has run, we can histogram the result as we like. For this, we need to select 1) which parameter we want to histogram (which in this case can only be 'radius'), and 2) how we would like to histogram this. Note that the report is not automatically generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram the result, This doesn't take so long and can be repeated as required.\n",
    "histRanges = pandas.DataFrame(\n",
    "    [\n",
    "        dict(\n",
    "            parameter=\"radius\",  # we only varied one parameter, so not much choice here\n",
    "            nBin=50,             # number of bins\n",
    "            binScale=\"log\",      # logarithmically spaced along x\n",
    "            binWeighting=\"vol\",  # volume weighting (only option as of yet)\n",
    "            autoRange=True,      # automatically sets min/max to histogram all\n",
    "        ),\n",
    "        dict(\n",
    "            parameter=\"radius\",  # same\n",
    "            nBin=20,             # but only 20 bins\n",
    "            binScale=\"linear\",   # linear x-axis spacing\n",
    "            presetRangeMin=3.14, # minimum\n",
    "            presetRangeMax=25,   # maximum (only first mode)\n",
    "            binWeighting=\"vol\",  # volume-weighted\n",
    "            autoRange=False,     # no auto-ranging (only a subset within the specified parameter range)\n",
    "        ),\n",
    "        dict(\n",
    "            parameter=\"radius\",\n",
    "            nBin=20,\n",
    "            binScale=\"linear\",\n",
    "            presetRangeMin=25,\n",
    "            presetRangeMax=75,\n",
    "            binWeighting=\"vol\",\n",
    "            autoRange=False,\n",
    "        ),\n",
    "\n",
    "        dict(\n",
    "            parameter=\"radius\",\n",
    "            nBin=20,\n",
    "            binScale=\"linear\",\n",
    "            presetRangeMin=75,\n",
    "            presetRangeMax=150,\n",
    "            binWeighting=\"vol\",\n",
    "            autoRange=False,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mcres = McAnalysis(resPath, md, histRanges, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the histogram result in a report similar to the original McSAS\n",
    "# Set up the plotting frame\n",
    "fhs, ahs = plt.subplots(\n",
    "    nrows = 2, \n",
    "    ncols = 1+len(histRanges), \n",
    "    figsize = [6 * (1+len(histRanges)), 5], \n",
    "    gridspec_kw={\n",
    "        'width_ratios':list(np.ones(len(histRanges) + 1)), \n",
    "        'height_ratios':[1,2]\n",
    "        }\n",
    "    )\n",
    "csfont = {'fontname':'Courier New'}\n",
    "\n",
    "\n",
    "# plot a histogram for every histRange:\n",
    "for histNum, histRange in histRanges.iterrows():\n",
    "    histDataFrame = mcres._averagedHistograms[histNum]\n",
    "    plt.sca(ahs[1, 1 + histNum])\n",
    "    plt.bar(\n",
    "        histDataFrame['xMean'], \n",
    "        histDataFrame['yMean'], \n",
    "        align = 'center', \n",
    "        width = histDataFrame['xWidth'],\n",
    "        yerr = histDataFrame['yStd'],\n",
    "        facecolor = 'orange',\n",
    "        edgecolor = 'black',\n",
    "        ecolor = 'red',\n",
    "        )\n",
    "    plt.xscale(histRange.binScale)\n",
    "    plt.xlabel('Size (nm)')\n",
    "    plt.ylabel('Volume fraction (arb. units)')\n",
    "\n",
    "    # get report, some string replacements to prevent errors of \"missing Glyph (9), which is the tab\"\n",
    "    histReport = mcres.debugReport(histNum)#.split('\\n', 1)[1]\n",
    "    plt.sca(ahs[0, 1 + histNum]) # top right\n",
    "    ahs[0,1 + histNum].set_aspect(1)\n",
    "    ahs[0,1 + histNum].axis('off')\n",
    "    ahs[0,1 + histNum].text(.2, 0, histReport, **csfont, \n",
    "        rotation=0,\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='bottom',\n",
    "        multialignment='left',\n",
    "        transform=ahs[0,1 + histNum].transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0)\n",
    "    )\n",
    "\n",
    "\n",
    "# plot data and fit:\n",
    "plt.sca(ahs[1, 0])\n",
    "mds.binnedData.plot('Q', 'I', yerr= 'ISigma', ax = ahs[1,0], label = 'Measured data', zorder = 1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Q (1/nm)')\n",
    "plt.ylabel('I (1/cm)')\n",
    "# plt.xlim(1e-1, 2)\n",
    "plt.plot(mcres._measData['Q'][0], mcres.modelIAvg.modelIMean.values, zorder = 2, label = 'McSAS3 result')\n",
    "plt.legend()\n",
    "\n",
    "# plot fitting statistics:\n",
    "runReport = mcres.debugRunReport().split('\\n', 1)[1]\n",
    "plt.sca(ahs[0, 0])\n",
    "ahs[0,0].set_aspect(1)\n",
    "ahs[0,0].axis('off')\n",
    "ahs[0,0].text(.2, 0, runReport, **csfont, \n",
    "    rotation=0,\n",
    "    horizontalalignment='center',\n",
    "    verticalalignment='bottom',\n",
    "    multialignment='left',\n",
    "    transform=ahs[0,0].transAxes,\n",
    "    bbox=dict(facecolor='white', alpha=0)\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# save into PDF:\n",
    "plt.savefig(Path(resPath.parent, resPath.stem+'.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
